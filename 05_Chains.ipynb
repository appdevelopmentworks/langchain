{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427f85b-8de9-414c-b379-d14e99f12e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe0d2b74-52db-4c2e-8c90-619f45d21831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\hartm\\anaconda3\\lib\\site-packages (0.1.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (0.0.34)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (0.1.50)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (0.1.49)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\hartm\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203cb4a-eb0a-42d0-a9e8-eec7a44e4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "#from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\n",
    "        \"product\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "result = chain.predict(product=\"iPhone\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cb1f32b-2fce-4a90-b47c-1072c1761bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n"
     ]
    }
   ],
   "source": [
    "#Gemini版\n",
    "#LLMChain,PromptTemplateをインポート\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "#GeminiのLangChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\n",
    "        \"product\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "#LLMChainを作成\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "result = chain.predict(product=\"iPhone\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83d67f73-ce76-4c05-9c3f-b5f87d622d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3miPhoneはどこの会社が開発した製品ですか？\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Apple\n"
     ]
    }
   ],
   "source": [
    "#Gemini版\n",
    "#LLMChain,PromptTemplateをインポート\n",
    "from langchain import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "#GeminiのLangChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\n",
    "        \"product\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "#LLMChainを作成\n",
    "chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = chain.predict(product=\"iPhone\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d16b90-88e3-4023-ab20-8e9c3acda08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=chat,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfd4f07-b832-4a84-90c3-69c7bba69e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "#GeminiのLangChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "chain = ConversationChain(\n",
    "    memory=memory,\n",
    "    llm=chat,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd9d464-c810-4c73-808d-e9681ed70a7d",
   "metadata": {},
   "source": [
    "### 特定の機能に特化したChains\n",
    "↓以下にアクセスし情報を元に答える\n",
    "https://www.jma.go.jp/bosai/forecast/data/overview_forecast/130000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219cc463-9adf-4a7f-9d0b-1c0edba68a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.jma.go.jp/bosai/forecast/data/overview_forecast/130000.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa968497-dfaf-4236-9647-84c89de996a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import LLMRequestsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"requests_result\"],\n",
    "    template=\"\"\"\n",
    "    以下の文章を元に質問に答えてください。\n",
    "    文章：{requests_result}\n",
    "    質問：{query}\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True    \n",
    ")\n",
    "\n",
    "chain = LLMRequestsChain(\n",
    "    llm_chain= llm_chain,\n",
    ")\n",
    "\n",
    "print(chain({\n",
    "    \"query\":\"東京の天気について教えて\",\n",
    "    \"url\":\"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/130000.json\",\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d29437e-24e5-449d-b051-b8085ebbf673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    以下の文章を元に質問に答えてください。\n",
      "    文章：{\"publishingOffice\":\"気象庁\",\"reportDatetime\":\"2024-04-30T16:33:00+09:00\",\"targetArea\":\"東京都\",\"headlineText\":\"\",\"text\":\"　関東の東には低気圧があって東北東へ進んでおり、前線が日本の南にのびています。\\n\\n　東京地方は、曇りとなっています。\\n\\n　３０日は、低気圧が関東の東を東北東へ進み、また、北海道付近へ進む低気圧からのびる寒冷前線が東日本を通過する見込みです。このため、曇りとなるでしょう。\\n\\n　５月１日は、前線や気圧の谷の影響を受ける見込みです。このため、雨明け方まで曇りとなるでしょう。伊豆諸島では、雨や雷雨となる所がある見込みです。\\n\\n【関東甲信地方】\\n　関東甲信地方は、曇りや晴れで雨の降っている所があります。\\n\\n　３０日は、低気圧が関東の東を東北東へ進み、また、北海道付近へ進む低気圧からのびる寒冷前線が東日本を通過する見込みです。このため、曇りで雨の降る所があるでしょう。\\n\\n　５月１日は、前線や気圧の谷の影響を受ける見込みです。このため、雨や曇りで、夜は伊豆諸島で雷を伴う所があるでしょう。\\n\\n　関東地方と伊豆諸島の海上では、３０日は波がやや高く、５月１日は、波が高いでしょう。また、所々で霧が発生しています。船舶は高波や視程障害に注意してください。\"}\n",
      "    質問：東京の天気について教えて\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'query': '東京の天気について教えて', 'url': 'https://www.jma.go.jp/bosai/forecast/data/overview_forecast/130000.json', 'output': '30日：曇り\\n5月1日：明け方まで曇り、伊豆諸島では雨や雷雨の可能性あり'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import LLMRequestsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "#GeminiのLangChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"requests_result\"],\n",
    "    template=\"\"\"\n",
    "    以下の文章を元に質問に答えてください。\n",
    "    文章：{requests_result}\n",
    "    質問：{query}\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=prompt,\n",
    "    verbose=True    \n",
    ")\n",
    "\n",
    "chain = LLMRequestsChain(\n",
    "    llm_chain= llm_chain,\n",
    ")\n",
    "\n",
    "print(chain({\n",
    "    \"query\":\"東京の天気について教えて\",\n",
    "    \"url\":\"https://www.jma.go.jp/bosai/forecast/data/overview_forecast/130000.json\",\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdfe83d-45ef-415b-b10a-ebd9212da681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "write_article_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"{input}についての記事を書いてください。\",\n",
    "        input_variables=[\"input\"],\n",
    "    ),\n",
    ") \n",
    "\n",
    "translate_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"以下の文章を英語に翻訳してください。\\n{input}\",\n",
    "        input_variables=[\"input\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "sequential_chain = SimpleSequentialChain(\n",
    "    chains=[\n",
    "        write_article_chain,\n",
    "        translate_chain,\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = sequential_chain.run(\"エレキギターの選び方\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c0bcdb3-494a-4474-8841-7a053b6ef8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**How to Choose an Electric Guitar**\n",
      "\n",
      "Choosing an electric guitar is a pivotal moment in your musical journey. Finding the right one will enhance your passion for playing and spark your creativity. Here are key factors to consider when choosing an electric guitar:\n",
      "\n",
      "**1. Purpose**\n",
      "\n",
      "What will you be using the guitar for? Recording, live performance, or practice? Your purpose will dictate the necessary features and specifications.\n",
      "\n",
      "**2. Budget**\n",
      "\n",
      "Electric guitars range in price from affordable models for beginners to high-end options for professionals. Set a budget and find the best guitar within that range.\n",
      "\n",
      "**3. Body Style**\n",
      "\n",
      "Electric guitars come in various body styles, such as Stratocaster, Telecaster, and Les Paul. Each style offers a unique sound, feel, and aesthetic.\n",
      "\n",
      "**4. Pickups**\n",
      "\n",
      "Pickups are the components that convert the vibrations of the guitar's strings into electrical signals. There are different types of pickups, such as single-coil, humbucker, and P-90, each with its own sonic characteristics.\n",
      "\n",
      "**5. Wood**\n",
      "\n",
      "The body and neck of a guitar are crafted from different woods, including maple, mahogany, and alder. Each wood imparts its own tonal and weight characteristics to the guitar.\n",
      "\n",
      "**6. Scale Length**\n",
      "\n",
      "The scale length is the distance from the nut to the bridge. Longer scale lengths create higher string tension, resulting in improved intonation and sustain.\n",
      "\n",
      "**7. Neck Shape**\n",
      "\n",
      "The neck shape determines how it fits in the player's hand. There are various shapes, such as C-shape, V-shape, and D-shape.\n",
      "\n",
      "**8. Finish**\n",
      "\n",
      "Electric guitars come in different finishes, such as polyurethane, lacquer, and oil. The finish affects the look and feel of the guitar.\n",
      "\n",
      "**9. Hardware**\n",
      "\n",
      "The guitar's hardware, such as the bridge, tuners, and nut, influences the guitar's playability and sound.\n",
      "\n",
      "**10. Amp Compatibility**\n",
      "\n",
      "Guitars are designed to be played through an amplifier. Consider the compatibility between the guitar and your amp to achieve the desired sound.\n",
      "\n",
      "**Tips:**\n",
      "\n",
      "* Try out different guitars if possible.\n",
      "* Consult with experienced musicians or guitar specialists.\n",
      "* Research online reviews and watch demo videos.\n",
      "* Thoroughly inspect the guitar before purchasing.\n",
      "* Finding the right guitar for you takes time and effort.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "#GeminiのLangChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "write_article_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"{input}についての記事を書いてください。\",\n",
    "        input_variables=[\"input\"],\n",
    "    ),\n",
    ") \n",
    "\n",
    "translate_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=PromptTemplate(\n",
    "        template=\"以下の文章を英語に翻訳してください。\\n{input}\",\n",
    "        input_variables=[\"input\"],\n",
    "    ),\n",
    ")\n",
    "\n",
    "sequential_chain = SimpleSequentialChain(\n",
    "    chains=[\n",
    "        write_article_chain,\n",
    "        translate_chain,\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = sequential_chain.run(\"エレキギターの選び方\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7915a93-e3c9-4a44-ac03-c2bb9de37621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
