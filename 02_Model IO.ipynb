{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95075c49-04fa-49eb-b83a-777f4ed52910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-9L6q6x7HCDtqe8gjBEvhHh8wAiDQQ\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1714818206,\n",
      "  \"model\": \"gpt-3.5-turbo-0125\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\\u9b5a\\u306f\\u57fa\\u672c\\u7684\\u306b\\u306f\\u6c34\\u4e2d\\u3067\\u305a\\u3063\\u3068\\u6cf3\\u304e\\u7d9a\\u3051\\u3066\\u3044\\u308b\\u305f\\u3081\\u3001\\u7720\\u308b\\u3068\\u3044\\u3046\\u6982\\u5ff5\\u304c\\u3042\\u307e\\u308a\\u3042\\u308a\\u307e\\u305b\\u3093\\u3002\\u305f\\u3060\\u3057\\u3001\\u4e00\\u90e8\\u306e\\u9b5a\\u985e\\u306f\\u4f11\\u606f\\u306e\\u305f\\u3081\\u306b\\u4f53\\u3092\\u5b89\\u5b9a\\u3055\\u305b\\u308b\\u5834\\u9762\\u304c\\u3042\\u308a\\u307e\\u3059\\u3002\\u4f8b\\u3048\\u3070\\u3001\\u30b5\\u30e1\\u306f\\u6c34\\u4e2d\\u3067\\u5b89\\u5b9a\\u3057\\u305f\\u4f4d\\u7f6e\\u306b\\u3068\\u3069\\u307e\\u308b\\u3053\\u3068\"\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"length\"\n",
      "    },\n",
      "    {\n",
      "      \"index\": 1,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\\u9b5a\\u306f\\u7761\\u7720\\u3068\\u3044\\u3046\\u3082\\u306e\\u3092\\u884c\\u3046\\u751f\\u7269\\u3067\\u306f\\u3042\\u308a\\u307e\\u305b\\u3093\\u3002\\u4ee3\\u308f\\u308a\\u306b\\u3001\\u9b5a\\u306f\\u4f11\\u606f\\u3092\\u3068\\u308b\\u305f\\u3081\\u306b\\u6c34\\u4e2d\\u3067\\u9759\\u6b62\\u3057\\u305f\\u308a\\u3001\\u307b\\u304b\\u306e\\u9b5a\\u3068\\u4e00\\u7dd2\\u306b\\u7fa4\\u308c\\u3092\\u4f5c\\u3063\\u305f\\u308a\\u3057\\u307e\\u3059\\u3002\\u3053\\u308c\\u3089\\u306e\\u884c\\u52d5\\u306f\\u3001\\u9b5a\\u304c\\u30a8\\u30cd\\u30eb\\u30ae\\u30fc\\u3092\\u7bc0\\u7d04\\u3057\\u3001\\u8eab\\u4f53\"\n",
      "      },\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"length\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 17,\n",
      "    \"completion_tokens\": 200,\n",
      "    \"total_tokens\": 217\n",
      "  },\n",
      "  \"system_fingerprint\": \"fp_3b956da36b\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "responce = openai.ChatCompletion.create(\n",
    "    model =\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":\"魚はいつ眠る？\"\n",
    "        },\n",
    "    ],\n",
    "    max_tokens=100,\n",
    "    temperature=1,\n",
    "    n=2,\n",
    ")\n",
    "\n",
    "print(responce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc965f5-25ee-464e-9ad7-6d79a71faf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.schema import AIMessage\n",
    "from langchain.schema import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d52895-c3c2-4ed6-9030-5f5a0f5e6d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hartm\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\hartm\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！お元気ですか？私はAIです。どうしたのですか？\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "#クライアント作成、呼び出すモデル指定\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "#実行\n",
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=\"こんにちは！\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed740c81-9dfa-4565-b667-7796cfdb416e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！元気ですか？何かお手伝いできることがありますか？\n"
     ]
    }
   ],
   "source": [
    "#Warningに基づきインポート文を変える\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "#クライアント作成、呼び出すモデル指定\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "#実行\n",
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=\"こんにちは！\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4371dd88-7852-4507-8238-76cdd8e8528f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "だし巻き卵の作り方は以下の通りです。\n",
      "\n",
      "材料:\n",
      "- 卵 4個\n",
      "- 砂糖 小さじ1\n",
      "- 醤油 小さじ1\n",
      "- だし 適量\n",
      "- 塩 適量\n",
      "- サラダ油 小さじ1\n",
      "\n",
      "作り方:\n",
      "1. 卵をボウルに割り、砂糖、醤油、だし、塩を加えてよく混ぜる。\n",
      "2. フライパンにサラダ油を熱し、卵液を流し入れる。\n",
      "3. 焼き目がつくまで弱火でじっくり焼く。\n",
      "4. 端から巻いていき、巻き終わりの部分に少し卵液を加えてしっかりと巻き付ける。\n",
      "5. さらに焼き目がつくまで焼いて完成。\n",
      "\n",
      "お好みで刻んだネギや青のりを散らしても美味しいです。ぜひお試しください。\n"
     ]
    }
   ],
   "source": [
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=\"だし巻き卵の作り方教えて\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4dc29b05-379d-4a4d-a73b-19130dda73a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to make dashimaki tamago\n"
     ]
    }
   ],
   "source": [
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=\"だし巻き卵の作り方教えて\"),\n",
    "        AIMessage(content=\"{ChatModelからの返答であるだし巻き卵の作り方}\"),\n",
    "        HumanMessage(content=\"英語に翻訳して\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d97e12f9-7db2-4791-948d-1e1b8622aad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！元気？\n"
     ]
    }
   ],
   "source": [
    "result = chat(\n",
    "    [\n",
    "        SystemMessage(content=\"あなたは親しい友人です。返答は敬語は使わず、フランクに会話してください\"),\n",
    "        HumanMessage(content=\"こんにちは！\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbab434-b5e8-46ea-ba4a-1523b6169468",
   "metadata": {},
   "source": [
    "## リスト形式で応答を受け取る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b3da4c0-7990-43e4-8f1c-496b03f52591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "代表的な製品=>iPhone\n",
      "代表的な製品=>iPad\n",
      "代表的な製品=>MacBook\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "#実行\n",
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=\"Appleが開発した代表的な製品を３つ教えてください\"),\n",
    "        HumanMessage(content=output_parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "output = output_parser.parse(result.content)\n",
    "\n",
    "for item in output:\n",
    "    print(\"代表的な製品=>\" + item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ef1d292-5b14-4494-8fe1-432195429245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "代表的な製品=>1. iPhone\n",
      "2. iPad\n",
      "3. Mac\n"
     ]
    }
   ],
   "source": [
    "#Geminiだとうまくいかない\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "#実行\n",
    "result = llm(\n",
    "    [\n",
    "        HumanMessage(content=\"Appleが開発した代表的な製品を３つ教えてください\"),\n",
    "        #Geminiでは、このパラメータでエラーになる\n",
    "        #HumanMessage(content=output_parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "output = output_parser.parse(result.content)\n",
    "\n",
    "for item in output:\n",
    "    print(\"代表的な製品=>\" + item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125cc6b9-d256-49d7-bfcb-71b8b0ccca65",
   "metadata": {},
   "source": [
    "## 文章の続きを考えさせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "484c7c57-0546-40ef-816c-4c16af56769a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hartm\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\hartm\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "食べに行きました\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "#モデルを指定\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "result = llm(\n",
    "    #入力テキスト\n",
    "    \"美味しいラーメンを\",\n",
    "    #生成をストップさせる文字列\n",
    "    stop = \"。\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e318f92-a9e6-4687-8b8c-c3196c9c1791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "食べに行きました\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "#モデルを指定\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "result = llm(\n",
    "    #入力テキスト\n",
    "    \"美味しいラーメンを\",\n",
    "    #生成をストップさせる文字列\n",
    "    stop = \"。\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49d45786-3648-4b2f-935f-6d8095394c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhoneはアメリカの企業であるApple（アップル）が開発した製品です。\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "#クライアント作成、呼び出すモデル指定\n",
    "chat = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\n",
    "        \"product\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=prompt.format(product=\"iPhone\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fe32f28-d279-4947-a6fb-94909993f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n"
     ]
    }
   ],
   "source": [
    "#Geminiの場合\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "#クライアント作成、呼び出すモデル指定\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\n",
    "        \"product\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = llm(\n",
    "    [\n",
    "        HumanMessage(content=prompt.format(product=\"iPhone\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29ce9237-ca74-4433-b6d7-1bac11ffcd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anthropicのチャットを使う場合\n",
    "from langchain.chat_models import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e5537-6cf2-4e01-89ac-f28c8fcde3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ローカルで使用可能なモデル\n",
    "from langchain.llms import GPT4All\n",
    "\n",
    "llm = GPT4All()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41219629-1a98-4171-a01c-7acb574ef92b",
   "metadata": {},
   "source": [
    "## キャッシュ機能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee815b16-9539-49bc-919a-46f3c5eee347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！お元気ですか？何かお手伝いできることはありますか？\n",
      "実行時間：1.3307714462280273秒\n",
      "こんにちは！お元気ですか？何かお手伝いできることはありますか？\n",
      "実行時間：0.001020669937133789秒\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "#キャッシュオブジェクト\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "start = time.time()\n",
    "result = chat([\n",
    "    HumanMessage(content=\"こんにちは！\")\n",
    "])\n",
    "end = time.time()\n",
    "\n",
    "print(result.content)\n",
    "print(f\"実行時間：{end -start}秒\")\n",
    "\n",
    "start = time.time()\n",
    "result = chat([\n",
    "    HumanMessage(content=\"こんにちは！\")\n",
    "])\n",
    "end = time.time()\n",
    "\n",
    "print(result.content)\n",
    "print(f\"実行時間：{end -start}秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "870f4d79-f2c1-4707-8afe-cf6ea8001ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！あなたとつながれてうれしいです。\n",
      "実行時間：1.0822279453277588秒\n",
      "こんにちは！あなたとつながれてうれしいです。\n",
      "実行時間：0.0秒\n"
     ]
    }
   ],
   "source": [
    "#Geminiの場合\n",
    "import time\n",
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "#キャッシュオブジェクト\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "#model= 明示的に引数を渡さないとエラーになる\n",
    "chat = ChatGoogleGenerativeAI(model='gemini-pro')\n",
    "\n",
    "start = time.time()\n",
    "result = chat([\n",
    "    HumanMessage(content=\"こんにちは！\")\n",
    "])\n",
    "end = time.time()\n",
    "\n",
    "print(result.content)\n",
    "print(f\"実行時間：{end -start}秒\")\n",
    "\n",
    "start = time.time()\n",
    "result = chat([\n",
    "    HumanMessage(content=\"こんにちは！\")\n",
    "])\n",
    "end = time.time()\n",
    "\n",
    "print(result.content)\n",
    "print(f\"実行時間：{end -start}秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d66b08b-02b5-43e7-a711-c6209c8857f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは！お手伝いしましょうか？\n",
      "実行時間：1.407752275466919秒\n",
      "こんにちは！お手伝いしましょうか？\n",
      "実行時間：0.9361052513122559秒\n"
     ]
    }
   ],
   "source": [
    "#Geminiの通常チャットだとキャッシュが効かない\n",
    "import time\n",
    "import langchain\n",
    "from langchain.cache import InMemoryCache\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "\n",
    "#chat = ChatOpenAI()\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "chat = model.start_chat()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\"\"\"\n",
    "result = chat([\n",
    "    HumanMessage(content=\"こんにちは！\")\n",
    "])\n",
    "\"\"\"\n",
    "\n",
    "result = chat.send_message(\"こんにちは！\")\n",
    "end = time.time()\n",
    "\n",
    "print(result.text)\n",
    "print(f\"実行時間：{end -start}秒\")\n",
    "\n",
    "start = time.time()\n",
    "\"\"\"\n",
    "result = chat([\n",
    "    HumanMessage(content=\"こんにちは！\")\n",
    "])\n",
    "\"\"\"\n",
    "result = chat.send_message(\"こんにちは！\")\n",
    "end = time.time()\n",
    "\n",
    "print(result.text)\n",
    "print(f\"実行時間：{end -start}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5930f4f2-d4a7-4ced-853f-312ba4d22eae",
   "metadata": {},
   "source": [
    "## 逐次応答表示（1文字づづ出力）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7883ba59-7dff-466e-951d-0cc79e12b093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美味しいステーキを焼くための基本的な手順を以下に示します。\n",
      "\n",
      "1. ステーキを室温に戻す：冷蔵庫から出して、室温に戻します。これにより、肉の中まで均一に火が通りやすくなります。\n",
      "\n",
      "2. 肉を塩コショウで下味をつける：ステーキに塩とコショウをまぶして、下味をつけます。塩を事前につけることで肉の旨みが引き立ちます。\n",
      "\n",
      "3. フライパンを熱する：フライパンを中火から強火にかけて熱し、しっかりと熱してから肉を入れます。\n",
      "\n",
      "4. 肉を焼く：肉をフライパンに入れ、片面を焼きます。焼き色がついたら裏返し、もう片面も焼きます。\n",
      "\n",
      "5. 火を止めて余熱で火を通す：ステーキを焼いた後、フライパンから取り出してアルミホイルなどで包み、数分間余熱で火を通します。\n",
      "\n",
      "6. カットして食べる：ステーキナイフで肉を適当な厚さにカットし、お皿に盛り付けて食べます。\n",
      "\n",
      "以上が美味しいステーキの焼き方の基本的な手順です。お好みの焼き加減や調味料でアレンジして、より美味しいステーキを楽しんでください。\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    #ストリーミングモード指定\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "#リクエスト\n",
    "resp = chat([\n",
    "    HumanMessage(content=\"美味しいステーキの焼き方教えて\")\n",
    "])\n",
    "\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da28e071-66dd-4ecc-8dce-5ba2b5aea91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**材料:**\n",
      "\n",
      "* 卵 3個\n",
      "* だし汁 100ml\n",
      "* 薄口しょうゆ 大さじ1\n",
      "* みりん 大さじ1\n",
      "* 砂糖 小さじ1\n",
      "* サラダ油 適量\n",
      "\n",
      "**作り方:**\n",
      "\n",
      "1. **卵液を作る:** ボウルに卵を割り入れ、だし汁、薄口しょうゆ、みりん、砂糖を加えて混ぜ合わせる。\n",
      "2. **卵焼き器を熱する:** 卵焼き器にサラダ油を薄く敷き、中火で熱する。\n",
      "3. **卵液を流し込む:** 熱した卵焼き器に卵液の1/3量を流し込む。\n",
      "4. **巻く:** 卵液が周りが固まってきたら、奥から手前に向けて巻く。\n",
      "5. **端を寄せる:** 巻いた卵を奥に寄せて、空いたスペースに卵液の2/3量を流し込む。\n",
      "6. **重ねて巻く:** 2/3量の卵液が固まってきたら、手前の卵焼きの上に重ねて巻く。\n",
      "7. **残りの卵液を流し込む:** 残り1/3量の卵液を流し込み、同様にして巻く。\n",
      "8. **形を整える:** 卵焼き器から取り出し、巻き簾に包んで形を整える。\n",
      "9. **冷ます:** 粗熱が取れるまで置いておく。\n",
      "10. **切る:** 食べやすい大きさに切る。\n",
      "\n",
      "**コツ:**\n",
      "\n",
      "* だし汁は、かつお節や昆布でとった本格的なものがおすすめ。\n",
      "* 卵焼き器は、テフロン加工のものを使うとくっつきにくいです。\n",
      "* 卵液を一度に流し込まないように注意し、少しずつ巻いていくのがポイント。\n",
      "* 巻き簾で形を整えると、きれいな円柱形になります。\n",
      "* 冷蔵庫で一晩寝かせると味がなじんでさらに美味しくなります。\n"
     ]
    }
   ],
   "source": [
    "#Geminiの場合一文字づつ表示されない\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\",\n",
    "    #model=\"gemini-1.5-pro\",\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "resp = chat([\n",
    "    HumanMessage(content=\"美味しいだし巻き卵の焼き方教えて\")\n",
    "])\n",
    "\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ebc304-95de-49d0-b1c9-ef4fa9dda19e",
   "metadata": {},
   "source": [
    "## 出力例を含んだプロンプト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c4ab3604-9f53-4da9-97b8-cf447ab6199f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatted_prompt:  以下の句読点の抜けた入力に句読点を追加してください。追加して良い句読点は「、」「。」のみです。他の句読点は追加しないでください。\n",
      "\n",
      "入力: LangChainはChatGPT・Large Language Model (LLM)の実利用をより柔軟に簡易に行うためのツール群です\n",
      "出力: LangChainは、ChatGPT・Large Language Model (LLM)の実利用をより柔軟に、簡易に行うためのツール群です。\n",
      "\n",
      "入力: 私はさまざまな機能がモジュールとして提供されているLangChainを使ってアプリケーションを開発しています\n",
      "出力:\n",
      "result:   私は、さまざまな機能がモジュールとして提供されているLangChainを使って、アプリケーションを開発しています。\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#応答例を示したプロンプト\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"LangChainはChatGPT・Large Language Model (LLM)の実利用をより柔軟に簡易に行うためのツール群です\", \n",
    "        \"output\": \"LangChainは、ChatGPT・Large Language Model (LLM)の実利用をより柔軟に、簡易に行うためのツール群です。\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#PromptTemplateの準備\n",
    "prompt = PromptTemplate(  \n",
    "    input_variables=[\"input\", \"output\"],  #← inputとoutputを入力変数として設定\n",
    "    template=\"入力: {input}\\n出力: {output}\",  #← テンプレート\n",
    ")\n",
    "\n",
    "#FewShotPromptTemplateの準備\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,  #← 入力例と出力例を定義\n",
    "    example_prompt=prompt,  #← FewShotPromptTemplateにPromptTemplateを渡す\n",
    "    prefix=\"以下の句読点の抜けた入力に句読点を追加してください。追加して良い句読点は「、」「。」のみです。他の句読点は追加しないでください。\",  #← 指示を追加する\n",
    "    suffix=\"入力: {input_string}\\n出力:\",  #← 出力例の入力変数を定義\n",
    "    input_variables=[\"input_string\"],  #← FewShotPromptTemplateの入力変数を設定\n",
    ")\n",
    "\n",
    "#\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo-instruct\"\n",
    ")\n",
    "#FewShotPromptTemplateを使ってプロンプトを作成\n",
    "formatted_prompt = few_shot_prompt.format(\n",
    "    input_string=\"私はさまざまな機能がモジュールとして提供されているLangChainを使ってアプリケーションを開発しています\"\n",
    ")\n",
    "\n",
    "result = llm.predict(formatted_prompt)\n",
    "print(\"formatted_prompt: \", formatted_prompt)\n",
    "print(\"result: \", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d2c43-eef6-4d3f-91e9-7463b568fb5a",
   "metadata": {},
   "source": [
    "## 追加で出力形式指定(結果を日付形式で受け取る)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "44e95ae8-ecb1-4bd3-bb89-f2f12e659289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0907-10-10 10:00:00\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "#Output ParserであるDatetimeOutputParserをインポート\n",
    "from langchain.output_parsers import DatetimeOutputParser  \n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "#DatetimeOutputParserを初期化\n",
    "output_parser = DatetimeOutputParser() \n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", )\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{product}のリリース日を教えて\")\n",
    "\n",
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=prompt.format(product=\"iPhone10\")),\n",
    "        #日付の出力形式を追加指定\n",
    "        HumanMessage(content=output_parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#出力結果を解析して日時形式に変換する\n",
    "output = output_parser.parse(result.content)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a784a87-ae28-4a20-b8c3-98ce72863dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geminiの場合、エラーになる\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "#Output ParserであるDatetimeOutputParserをインポート\n",
    "from langchain.output_parsers import DatetimeOutputParser  \n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "#DatetimeOutputParserを初期化\n",
    "output_parser = DatetimeOutputParser() \n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{product}のリリース日を教えて\")\n",
    "\n",
    "result = chat(\n",
    "    [\n",
    "        HumanMessage(content=prompt.format(product=\"iPhone10\")),\n",
    "        #日付の出力形式を追加指定\n",
    "        HumanMessage(content=output_parser.get_format_instructions()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#出力結果を解析して日時形式に変換する\n",
    "output = output_parser.parse(result.content)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c1bdc-5a08-4925-96db-9947481cd37d",
   "metadata": {},
   "source": [
    "## 出力形式を自分で定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7e742947-0c16-4e6a-88d2-c4b91105f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル名: Samsung Galaxy S21 Ultra\n",
      "インストールされているOS: Android 11\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "class Smartphone(BaseModel): #← Pydanticのモデルを定義する\n",
    "    release_date: str = Field(description=\"スマートフォンの発売日\") #← Fieldを使って説明を追加する\n",
    "    screen_inches: float = Field(description=\"スマートフォンの画面サイズ(インチ)\")\n",
    "    os_installed: str = Field(description=\"スマートフォンにインストールされているOS\")\n",
    "    model_name: str = Field(description=\"スマートフォンのモデル名\")\n",
    "\n",
    "    @validator(\"screen_inches\") #← validatorを使って値を検証する\n",
    "    def validate_screen_inches(cls, field): #← validatorの引数には、検証するフィールドと値が渡される\n",
    "        if field <= 0: #← screen_inchesが0以下の場合はエラーを返す\n",
    "            raise ValueError(\"Screen inches must be a positive number\")\n",
    "        return field\n",
    "\n",
    "\n",
    "#PydanticOutputParserをSmartPhoneクラスで初期化する\n",
    "parser = PydanticOutputParser(pydantic_object=Smartphone) \n",
    "\n",
    "#Chat modelsにHumanMessageを渡して、文章を生成する\n",
    "result = chat([ \n",
    "    HumanMessage(content=\"Androidでリリースしたスマートフォンを1個挙げて\"),\n",
    "    HumanMessage(content=parser.get_format_instructions())\n",
    "])\n",
    "\n",
    "#PydanticOutputParserを使って、文章をパースする\n",
    "parsed_result = parser.parse(result.content) \n",
    "#出力\n",
    "print(f\"モデル名: {parsed_result.model_name}\")\n",
    "print(f\"インストールされているOS: {parsed_result.os_installed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f86341-7d61-406b-a4db-6f1254eeb11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geminiの場合エラーになる\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "class Smartphone(BaseModel): #← Pydanticのモデルを定義する\n",
    "    release_date: str = Field(description=\"スマートフォンの発売日\") #← Fieldを使って説明を追加する\n",
    "    screen_inches: float = Field(description=\"スマートフォンの画面サイズ(インチ)\")\n",
    "    os_installed: str = Field(description=\"スマートフォンにインストールされているOS\")\n",
    "    model_name: str = Field(description=\"スマートフォンのモデル名\")\n",
    "\n",
    "    @validator(\"screen_inches\") #← validatorを使って値を検証する\n",
    "    def validate_screen_inches(cls, field): #← validatorの引数には、検証するフィールドと値が渡される\n",
    "        if field <= 0: #← screen_inchesが0以下の場合はエラーを返す\n",
    "            raise ValueError(\"Screen inches must be a positive number\")\n",
    "        return field\n",
    "\n",
    "\n",
    "#PydanticOutputParserをSmartPhoneクラスで初期化する\n",
    "parser = PydanticOutputParser(pydantic_object=Smartphone) \n",
    "\n",
    "#Chat modelsにHumanMessageを渡して、文章を生成する\n",
    "result = chat([ \n",
    "    HumanMessage(content=\"Androidでリリースしたスマートフォンを1個挙げて\"),\n",
    "    HumanMessage(content=parser.get_format_instructions())\n",
    "])\n",
    "\n",
    "#PydanticOutputParserを使って、文章をパースする\n",
    "parsed_result = parser.parse(result.content) \n",
    "#出力\n",
    "print(f\"モデル名: {parsed_result.model_name}\")\n",
    "print(f\"インストールされているOS: {parsed_result.os_installed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ed620-2d5f-4581-8747-6e6e5364b055",
   "metadata": {},
   "source": [
    "## 誤ったっ結果が返ったとき修正できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "00dc5781-c997-4f33-b878-574d7fb0aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデル名: Samsung Galaxy S21 Ultra\n",
      "画面サイズ: 6.7インチ\n",
      "OS: Android 11\n",
      "スマートフォンの発売日: 2021-09-15\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.output_parsers import OutputFixingParser  #←OutputFixingParserを追加\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "class Smartphone(BaseModel):\n",
    "    release_date: str = Field(description=\"スマートフォンの発売日\")\n",
    "    screen_inches: float = Field(description=\"スマートフォンの画面サイズ(インチ)\")\n",
    "    os_installed: str = Field(description=\"スマートフォンにインストールされているOS\")\n",
    "    model_name: str = Field(description=\"スマートフォンのモデル名\")\n",
    "\n",
    "    @validator(\"screen_inches\")\n",
    "    def validate_screen_inches(cls, field):\n",
    "        if field <= 0:\n",
    "            raise ValueError(\"Screen inches must be a positive number\")\n",
    "        return field\n",
    "\n",
    "\n",
    "parser = OutputFixingParser.from_llm(  #← OutputFixingParserを使用するように書き換え\n",
    "    parser=PydanticOutputParser(pydantic_object=Smartphone),  #← parserを設定\n",
    "    llm=chat  #← 修正に使用する言語モデルを設定\n",
    ")\n",
    "\n",
    "result = chat([HumanMessage(content=\"Androidでリリースしたスマートフォンを1個挙げて\"), HumanMessage(content=parser.get_format_instructions())])\n",
    "\n",
    "parsed_result = parser.parse(result.content)\n",
    "\n",
    "print(f\"モデル名: {parsed_result.model_name}\")\n",
    "print(f\"画面サイズ: {parsed_result.screen_inches}インチ\")\n",
    "print(f\"OS: {parsed_result.os_installed}\")\n",
    "print(f\"スマートフォンの発売日: {parsed_result.release_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632eb448-f65f-4714-8056-dbe3497441f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geminiバージョンはエラー\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import OutputFixingParser  #←OutputFixingParserを追加\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.schema import HumanMessage\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "class Smartphone(BaseModel):\n",
    "    release_date: str = Field(description=\"スマートフォンの発売日\")\n",
    "    screen_inches: float = Field(description=\"スマートフォンの画面サイズ(インチ)\")\n",
    "    os_installed: str = Field(description=\"スマートフォンにインストールされているOS\")\n",
    "    model_name: str = Field(description=\"スマートフォンのモデル名\")\n",
    "\n",
    "    @validator(\"screen_inches\")\n",
    "    def validate_screen_inches(cls, field):\n",
    "        if field <= 0:\n",
    "            raise ValueError(\"Screen inches must be a positive number\")\n",
    "        return field\n",
    "\n",
    "\n",
    "parser = OutputFixingParser.from_llm(  #← OutputFixingParserを使用するように書き換え\n",
    "    parser=PydanticOutputParser(pydantic_object=Smartphone),  #← parserを設定\n",
    "    llm=chat  #← 修正に使用する言語モデルを設定\n",
    ")\n",
    "\n",
    "result = chat([HumanMessage(content=\"Androidでリリースしたスマートフォンを1個挙げて\"), HumanMessage(content=parser.get_format_instructions())])\n",
    "\n",
    "parsed_result = parser.parse(result.content)\n",
    "\n",
    "print(f\"モデル名: {parsed_result.model_name}\")\n",
    "print(f\"画面サイズ: {parsed_result.screen_inches}インチ\")\n",
    "print(f\"OS: {parsed_result.os_installed}\")\n",
    "print(f\"スマートフォンの発売日: {parsed_result.release_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c85288-5d42-464b-a79b-7ea62a73276d",
   "metadata": {},
   "source": [
    "# Geminiの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a52c2e11-b125-4ac7-b263-9a815a4a311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、ご機嫌いかがですか？\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "\n",
    "#クライアント作成、呼び出すモデル指定\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\"\n",
    ")\n",
    "#実行\n",
    "result = llm(\n",
    "    [\n",
    "        HumanMessage(content=\"こんにちは！\")\n",
    "    ]\n",
    ")\n",
    "#出力\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118605af-e5aa-4610-b45e-c046723caaae",
   "metadata": {},
   "source": [
    "## OpenAI、Gemini共通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f2d0198-44aa-42ff-bae0-dafd5748b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ユーザー、アシスタント、システムメッセージをインポート\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94355914-6410-4792-8932-75b549c2cd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Ingredients:**\n",
      "\n",
      "- 2 large eggs\n",
      "- 1/4 cup dashi (Japanese soup stock)\n",
      "- 1 tablespoon soy sauce\n",
      "- 1 tablespoon mirin (Japanese sweet cooking wine)\n",
      "- 1/4 teaspoon sugar\n",
      "- Vegetable oil, for greasing the pan\n",
      "\n",
      "**Instructions:**\n",
      "\n",
      "1. In a medium bowl, whisk together the eggs, dashi, soy sauce, mirin, and sugar.\n",
      "2. Heat a nonstick skillet over medium heat. Grease the pan with vegetable oil.\n",
      "3. Pour a thin layer of the egg mixture into the heated pan.\n",
      "4. Cook for 1-2 minutes, or until the edges are set and the center is slightly runny.\n",
      "5. Using a spatula, gently roll up the omelet from one end to the other.\n",
      "6. Slide the rolled omelet to one side of the pan.\n",
      "7. Pour another thin layer of egg mixture into the pan and cook as before.\n",
      "8. Repeat steps 5-7 until all of the egg mixture is used up.\n",
      "9. Transfer the omelet to a cutting board and let it cool slightly before slicing and serving.\n"
     ]
    }
   ],
   "source": [
    "result = llm(\n",
    "    [\n",
    "        HumanMessage(content=\"だし巻き卵の作り方教えて\"),\n",
    "        AIMessage(content=\"{llmからの返答であるだし巻き卵の作り方}\"),\n",
    "        HumanMessage(content=\"英語に翻訳して\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294a0b6-98c5-48bc-a17f-f737ebac00b5",
   "metadata": {},
   "source": [
    "## 役割を与えて応答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17419064-43d2-4093-88aa-09f8745526f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**朝食**\n",
      "\n",
      "* オートミール、ベリー、ナッツ入り\n",
      "* 全粒粉トースト、アボカド、卵\n",
      "* ギリシャヨーグルト、フルーツ、グラノーラ\n",
      "\n",
      "**昼食**\n",
      "\n",
      "* サラダ（葉物野菜、グリルした鶏肉、全粒穀物、野菜）\n",
      "* サンドイッチ（全粒粉パン、赤身のタンパク質、野菜）\n",
      "* スープとサラダの組み合わせ\n",
      "\n",
      "**夕食**\n",
      "\n",
      "* 焼き鮭、玄米、蒸し野菜\n",
      "* 鶏肉のグリル、焼き芋、ブロッコリー\n",
      "* レンズ豆のスープ、全粒粉パン\n",
      "\n",
      "**間食**\n",
      "\n",
      "* フルーツ（りんご、バナナ、ベリー）\n",
      "* 野菜（ニンジン、セロリ、キュウリ）\n",
      "* ヨーグルト\n",
      "* ナッツと種\n",
      "\n",
      "**追加のヒント**\n",
      "\n",
      "* 1日に5～6回の少量の食事を食べる。\n",
      "* 全粒穀物、果物、野菜を多く含める。\n",
      "* 赤身のタンパク質（鶏肉、魚、豆類）を選ぶ。\n",
      "* 砂糖分の多い飲み物や加工食品は避ける。\n",
      "* 食物繊維を十分に摂取する（1日あたり25～30グラム）。\n",
      "* 食事療法を管理するために血糖値を定期的に測定する。\n",
      "\n",
      "**留意事項**\n",
      "\n",
      "この献立はあくまでサンプルであり、個々のニーズによって調整する必要があります。糖尿病患者は、食事療法を計画する前に医療従事者に相談することが重要です。\n"
     ]
    }
   ],
   "source": [
    "result = llm(\n",
    "    [\n",
    "        SystemMessage(content=\"あなたは管理栄養士です\"),\n",
    "        HumanMessage(content=\"糖尿病患者むけの献立を考えてください\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8136b95-2155-47ca-9af1-7bc35ea23935",
   "metadata": {},
   "source": [
    "## プロンプトテンプレート使い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bed0eba9-11f0-4a75-a5aa-b0195d6ff5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "14a2160c-85b4-4fbd-a22a-4443c369d7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhoneはどこの会社が開発した製品ですか？\n",
      "AQUOSはどこの会社が開発した製品ですか？\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"{product}はどこの会社が開発した製品ですか？\",\n",
    "    input_variables=[\n",
    "        \"product\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(prompt.format(product=\"iPhone\"))\n",
    "print(prompt.format(product=\"AQUOS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "800d47bb-cf1b-4b2f-9b81-10118fe05322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#プロンプトをJson形式で保存\n",
    "prompt_json = prompt.save(\"prompt.json\")\n",
    "prompt_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6dd407dc-8f10-44c0-b00b-e7fca96e9668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQUOSはどこの会社が開発した製品ですか？\n"
     ]
    }
   ],
   "source": [
    "#プロンプトJSONファイルを読み込むライブラリ\n",
    "from langchain.prompts import load_prompt\n",
    "#\n",
    "loaded_prompt = load_prompt(\"prompt.json\")\n",
    "#読み込んでパラメータを渡して表示\n",
    "print(loaded_prompt.format(product=\"AQUOS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03d9a1-c7fc-4426-af76-a158871071b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#エラーになる\n",
    "print(prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe89e3f-00d7-4a7d-922f-3d4319e105ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
